{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Intervention System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print (\"Student data read successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students （number of datapoints): 395\n",
      "Number of features: 30\n",
      "Number of students who passed (graduates): 265\n",
      "Number of students who failed (non-graduates): 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = len(student_data)\n",
    "n_features = len(student_data.iloc[0]) - 1\n",
    "n_passed = len(student_data[student_data['passed'] == 'yes'])\n",
    "n_failed = len(student_data[student_data['passed'] == 'no'])\n",
    "grad_rate = float(n_passed)/n_students * 100\n",
    "\n",
    "print(\"Total number of students （number of datapoints): {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed (graduates): {}\".format(n_passed))\n",
    "print(\"Number of students who failed (non-graduates): {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature PreProceesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "num_train = 300\n",
    "\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train, test_size=num_test)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    \n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    \n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a RandomForestClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0360 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.9925.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7015.\n",
      "\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0240 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.9887.\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for test set: 0.7344.\n",
      "\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0240 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.9927.\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for test set: 0.7132.\n",
      "\n",
      "\n",
      "Training a GaussianNB using a training set size of 100. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.3953.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.4096.\n",
      "\n",
      "\n",
      "Training a GaussianNB using a training set size of 200. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8045.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7176.\n",
      "\n",
      "\n",
      "Training a GaussianNB using a training set size of 300. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.8104.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7612.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 100. . .\n",
      "Trained model in 0.5316 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.8828.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7597.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 200. . .\n",
      "Trained model in 0.0035 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8403.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7368.\n",
      "\n",
      "\n",
      "Training a LogisticRegression using a training set size of 300. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0018 seconds.\n",
      "F1 score for training set: 0.8416.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7536.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_A = RandomForestClassifier(random_state=0)\n",
    "clf_B = GaussianNB()\n",
    "clf_C = LogisticRegression(random_state=0)\n",
    "\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    for j in [(X_train_100, y_train_100), (X_train_200, y_train_200), (X_train_300, y_train_300)]:\n",
    "        train_predict(clf, j[0], j[1], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a DecisionTreeClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7377.\n",
      "\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.5983.\n",
      "\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0055 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.6116.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0760 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8121.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7712.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8012.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7662.\n",
      "\n",
      "\n",
      "Training a SGDClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8194.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7368.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 100. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.8590.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7917.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 200. . .\n",
      "Trained model in 0.0080 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.8471.\n",
      "Made predictions in 0.0051 seconds.\n",
      "F1 score for test set: 0.7703.\n",
      "\n",
      "\n",
      "Training a SVC using a training set size of 300. . .\n",
      "Trained model in 0.0118 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.8655.\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for test set: 0.7651.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0016 seconds.\n",
      "F1 score for training set: 0.8243.\n",
      "Made predictions in 0.0036 seconds.\n",
      "F1 score for test set: 0.7429.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for training set: 0.8140.\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for test set: 0.7647.\n",
      "\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0120 seconds.\n",
      "F1 score for training set: 0.8725.\n",
      "Made predictions in 0.0040 seconds.\n",
      "F1 score for test set: 0.7857.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "clf_A = DecisionTreeClassifier(random_state=0)\n",
    "clf_B = SGDClassifier(random_state=0)\n",
    "clf_C = SVC(random_state=0)\n",
    "clf_D = KNeighborsClassifier()\n",
    "\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    for j in [(X_train_100, y_train_100), (X_train_200, y_train_200), (X_train_300, y_train_300)]:\n",
    "        train_predict(clf, j[0], j[1], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'penalty': ['l2', 'l1'], 'C': [1, 10, 100, 1000]},\n",
      "       pre_dispatch='2*n_jobs', refit=True,\n",
      "       scoring=make_scorer(f1_score, pos_label=yes), verbose=0)\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score:  0.77\n",
      "Made predictions in 0.0000 seconds.\n",
      "Tuned model has a training F1 score of 0.8463.\n",
      "Score:  0.6526315789473685\n",
      "Made predictions in 0.0000 seconds.\n",
      "Tuned model has a testing F1 score of 0.7591.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    score = clf.score(features, target.values)\n",
    "    end = time()\n",
    "    print(\"Score: \", score)\n",
    "    \n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "parameters = { \"penalty\":[\"l2\",\"l1\"], \n",
    "               \"C\":[1,10,100,1000],\n",
    "              }\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=f1_scorer)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "print(grid_obj)\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n",
    "\n",
    "print(\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print(\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
